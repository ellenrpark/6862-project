{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number training points:  38170\n",
      "Total # Data points:  42412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/BCenv/lib/python3.7/site-packages/ipykernel_launcher.py:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Month encoding:  raw\n",
      "Date encoding:  thermometer\n",
      "\n",
      "Cross validation with k-folding:  10\n",
      "\n",
      "%% PHOSPHATE %%\n",
      "train score:  [0.20721148 0.2054795  0.20579027 0.20677529 0.20457994 0.20994966\n",
      " 0.20737366 0.20331931 0.20579114 0.20715652]\n",
      "test score:  [0.19887143 0.21439687 0.21167109 0.20292403 0.22244788 0.17421272\n",
      " 0.19738173 0.23385983 0.21168034 0.19939433]\n",
      "Estimator:  [ 6.48936055e-02 -3.78875771e-01  5.08146984e-02 -2.97738989e-01\n",
      "  6.34369595e-01 -2.62433121e-04 -1.37446874e-04  2.37197021e-03\n",
      "  1.11566315e-03  2.70541572e-02 -1.23513741e-02 -2.78952156e-02\n",
      " -3.00209585e-02 -6.47497104e-02 -2.01582820e-02 -2.57316850e-02\n",
      " -1.73084944e-02 -3.21502770e-02  1.89245692e-01]\n",
      "R2 values:  0.794592409936261\n",
      "testing error:  0.07644379581084658\n",
      "Dropout E:  0.013826176192041259\n",
      "Dropout Var:  1.2926484669951699\n",
      "\n",
      "%% SILICATE %%\n",
      "train score:  [0.23345195 0.23299147 0.23257289 0.23304231 0.23276532 0.23414145\n",
      " 0.23292141 0.23225423 0.23288075 0.23340067]\n",
      "test score:  [0.22966454 0.23379042 0.23756445 0.23330049 0.23577365 0.22336676\n",
      " 0.23439707 0.24042698 0.23478153 0.23009282]\n",
      "Estimator:  [ 3.82005323e-01 -4.28328204e-01  3.96679139e-01 -1.50643254e-01\n",
      "  2.28396090e-01 -1.27471540e-03 -1.48167546e-04 -4.97325066e-03\n",
      "  6.14135655e-03  7.74640484e-02  1.54395519e-02 -1.57625645e-01\n",
      " -2.14062767e-02  4.24145585e-03  2.25222264e-03  1.12084797e-02\n",
      " -1.53014778e-02 -3.32420174e-02  6.78275088e-02]\n",
      "R2 values:  0.7673823298990727\n",
      "testing error:  0.12552167043287768\n",
      "Dropout E:  0.005010649991316082\n",
      "Dropout Var:  1.2886570970020816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%` not found.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_validate,cross_val_score\n",
    "import torch\n",
    "\n",
    "InputDataDir='data/GOSHIP_Data/QCFilteredData.csv'\n",
    "FigDir = 'figures/LinearRegression_wDropOut/'\n",
    "\n",
    "pos_encode=['raw','radians']\n",
    "date_encode=['thermometer','sincos']\n",
    "\n",
    "P_cv_scores = np.zeros((len(pos_encode), len(date_encode)))\n",
    "P_cv_scores[:]=np.NaN\n",
    "\n",
    "P_cv_Rscores = np.zeros((len(pos_encode), len(date_encode)))\n",
    "P_cv_Rscores[:]=np.NaN\n",
    "\n",
    "P_cv_var = np.zeros((len(pos_encode), len(date_encode)))\n",
    "P_cv_var[:]=np.NaN\n",
    "\n",
    "S_cv_scores = np.zeros((len(pos_encode), len(date_encode)))\n",
    "S_cv_scores[:]=np.NaN\n",
    "\n",
    "S_cv_Rscores = np.zeros((len(pos_encode), len(date_encode)))\n",
    "S_cv_Rscores[:]=np.NaN\n",
    "\n",
    "S_cv_var = np.zeros((len(pos_encode), len(date_encode)))\n",
    "S_cv_var[:]=np.NaN\n",
    "\n",
    "P_models=[[]]*(len(pos_encode)*len(date_encode))\n",
    "S_models=[[]]*(len(pos_encode)*len(date_encode))\n",
    "\n",
    "train_val = int(np.floor(0.9*pd.read_csv(InputDataDir).shape[0]))\n",
    "print('Number training points: ',train_val)\n",
    "print('Total # Data points: ', pd.read_csv(InputDataDir).shape[0])\n",
    "k=10\n",
    "\n",
    "z=0\n",
    "def mean_square_scorer(clf, X, y):\n",
    "    y_pred = clf.predict(X)\n",
    "    cm = mean_squared_error(y, y_pred)\n",
    "    return cm\n",
    "\n",
    "def BernMask(ind, p):\n",
    "    import torch\n",
    "    init_p = torch.empty(len(ind),1)\n",
    "    init_p[:] = p\n",
    "    bmask = torch.bernoulli(init_p)\n",
    "    bmask=np.array(bmask)\n",
    "    #print(bmask)\n",
    "    \n",
    "    return bmask\n",
    "\n",
    "p = 0.7\n",
    "\n",
    "i = 0 \n",
    "j = 0\n",
    "# Load data\n",
    "GOSHIP_Data=pd.read_csv(InputDataDir)\n",
    "GOSHIP_Data=GOSHIP_Data.iloc[:,3:]\n",
    "\n",
    "# Shuffle data\n",
    "GOSHIP_Data = GOSHIP_Data.sample(frac=1)\n",
    "\n",
    "Position_Data = GOSHIP_Data.loc[:,['LATITUDE','LONGITUDE']]\n",
    "Date_Data = GOSHIP_Data.loc[:,'MONTH']\n",
    "\n",
    "# Standardize non-position/datae data\n",
    "scaler = StandardScaler().fit(GOSHIP_Data.iloc[:,2:-1])\n",
    "data_scaled = scaler.transform(GOSHIP_Data.iloc[:,2:-1])\n",
    "data_scaled = pd.DataFrame(data_scaled, columns = ['PRES','TEMP','SAL','OXY','NITR','PHSP','SILI'])\n",
    "\n",
    "# Get X data\n",
    "X=data_scaled.iloc[:,0:5] # Pres, temp, sal , oxy, nitr\n",
    "\n",
    "# Encode position data and add it to X-data\n",
    "if pos_encode[i]=='none':\n",
    "    # Do not include postion data\n",
    "    pass\n",
    "elif pos_encode[i]=='raw':\n",
    "    # Use raw lat/lon data\n",
    "    X['LAT']=GOSHIP_Data.loc[:,'LATITUDE'].to_numpy()\n",
    "    X['LON']=GOSHIP_Data.loc[:,'LONGITUDE'].to_numpy()\n",
    "elif pos_encode[i]=='radians':\n",
    "    # Use lat/lon encoded as radians\n",
    "    X['LAT']=np.radians(GOSHIP_Data.loc[:,'LATITUDE'].to_numpy())\n",
    "    X['LON']=np.radians(GOSHIP_Data.loc[:,'LONGITUDE'].to_numpy())\n",
    "\n",
    "# Encode date data and add it to X-data\n",
    "if date_encode[i]== 'none':\n",
    "    pass\n",
    "elif date_encode[i]== 'thermometer':\n",
    "    non_data=GOSHIP_Data.loc[:,'MONTH'].to_numpy()\n",
    "    temp_data=np.zeros((len(non_data), 12))\n",
    "    for m in np.arange(len(temp_data)):\n",
    "        m_ind=non_data[m]  \n",
    "        temp_data[m,:m_ind]=1\n",
    "\n",
    "    EncodedFeatures=pd.DataFrame(temp_data, columns=['M1','M2','M3', 'M4', 'M5','M6', 'M7', 'M8', 'M9','M10','M11', 'M12'])\n",
    "    #print(EncodedFeatures)\n",
    "    X=pd.concat([X,EncodedFeatures], axis=1)\n",
    "    #print(X)\n",
    "elif date_encode[i]== 'sincos':\n",
    "    # Encode as a sin/cosine pair\n",
    "    X['MONTH_SIN']=np.sin((2*np.pi*GOSHIP_Data.loc[:,'MONTH'])/max(GOSHIP_Data.loc[:,'MONTH']))\n",
    "    X['MONTH_COS']=np.cos((2*np.pi*GOSHIP_Data.loc[:,'MONTH'])/max(GOSHIP_Data.loc[:,'MONTH']))\n",
    "\n",
    "# Get Y data\n",
    "Y_P = data_scaled.loc[:,'PHSP']\n",
    "Y_S = data_scaled.loc[:, 'SILI']\n",
    "\n",
    "# Run regression\n",
    "print('\\nMonth encoding: ', pos_encode[i])\n",
    "print('Date encoding: ', date_encode[j])\n",
    "\n",
    "# Split in to test and train values\n",
    "X_train = X.iloc[:train_val,:]\n",
    "X_test=X.iloc[train_val:, :]\n",
    "\n",
    "Y_P_train=Y_P.iloc[:train_val]\n",
    "Y_P_test=Y_P.iloc[train_val:]\n",
    "\n",
    "Y_S_train=Y_S.iloc[:train_val]\n",
    "Y_S_test=Y_S.iloc[train_val:]\n",
    "\n",
    "ColVal=X.columns.to_list()\n",
    "IndexList=X_train.index.to_list()\n",
    "\n",
    "# For dropout, apply bernoulli mask to training data\n",
    "init_p = torch.empty(X_train.shape)\n",
    "init_p[:] = p\n",
    "bmask_train_array = torch.bernoulli(init_p)\n",
    "bmask_train_array=np.array(bmask_train_array)\n",
    "\n",
    "bmask_train_df=pd.DataFrame(bmask_train_array, index=IndexList, columns=ColVal)\n",
    "X_train=X_train*bmask_train_df\n",
    "# Print Linear regression with cross validation \n",
    "linear=LinearRegression()\n",
    "cv_results_P = cross_validate(linear, X_train, Y_P_train, cv=k,return_train_score=True, scoring=mean_square_scorer, return_estimator=True)\n",
    "cv_results_S = cross_validate(linear, X_train, Y_S_train, cv=k,return_train_score=True,scoring=mean_square_scorer, return_estimator=True)\n",
    "\n",
    "print('\\nCross validation with k-folding: ', k)\n",
    "print('\\n%% PHOSPHATE %%')\n",
    "print('train score: ', cv_results_P['train_score'])\n",
    "print('test score: ', cv_results_P['test_score'])\n",
    "\n",
    "# Select the one with the lowest scores\n",
    "print('Estimator: ', cv_results_P['estimator'][np.argmin(cv_results_P['test_score'])].coef_)\n",
    "best_P_model = cv_results_P['estimator'][np.argmin(cv_results_P['test_score'])]\n",
    "print('R2 values: ',best_P_model.score(X_train,Y_P_train))\n",
    "P_models[z]=best_P_model\n",
    "# Test this model and calculate MSE on test data\n",
    "P_pred_test_cv=best_P_model.predict(X_test)\n",
    "P_cv_Rscores[i,j]=best_P_model.score(X_train,Y_P_train)\n",
    "P_cv_scores[i,j]=mean_squared_error(Y_P_test, P_pred_test_cv)\n",
    "print('testing error: ', mean_squared_error(Y_P_test, P_pred_test_cv))\n",
    "\n",
    "## Droup out testing\n",
    "# Calculate E\n",
    "f_i_P=np.zeros(Y_P_test.shape[0])\n",
    "f_i_P[:]=np.NaN\n",
    "for k in np.arange(Y_P_test.shape[0]):\n",
    "    bmask = BernMask(ind=X.columns.to_list(), p=p)\n",
    "\n",
    "    old_coef_P=best_P_model.coef_.reshape((best_P_model.coef_.shape[0],1))\n",
    "    #print(old_coef_P*bmask)\n",
    "    new_coef_P = old_coef_P*bmask\n",
    "    const_P =best_P_model.intercept_\n",
    "    #print('New coef: ', new_coef_P)\n",
    "\n",
    "    # Evaluate new value of P with masked coeff\n",
    "    x_i = X_test.iloc[k,:].to_numpy()\n",
    "    x_i = x_i.reshape((x_i.shape[0],1))\n",
    "    f_i_P[k]=np.dot(new_coef_P.T, x_i)[0,0]+const_P\n",
    "\n",
    "E_P=np.nanmean(f_i_P)\n",
    "var_P = np.nanmean((P_pred_test_cv**2 - E_P**2))\n",
    "P_cv_var[i,j]=var_P\n",
    "\n",
    "print('Dropout E: ', E_P)\n",
    "print('Dropout Var: ', var_P)\n",
    "\n",
    "print('\\n%% SILICATE %%')\n",
    "\n",
    "print('train score: ', cv_results_S['train_score'])\n",
    "print('test score: ', cv_results_S['test_score'])\n",
    "print('Estimator: ', cv_results_S['estimator'][np.argmin(cv_results_S['test_score'])].coef_)\n",
    "best_S_model = cv_results_S['estimator'][np.argmin(cv_results_S['test_score'])]\n",
    "print('R2 values: ',best_S_model.score(X_train,Y_S_train))\n",
    "S_pred_test_cv=best_S_model.predict(X_test)\n",
    "S_cv_Rscores[i,j]=best_S_model.score(X_train,Y_S_train)\n",
    "S_cv_scores[i,j]=mean_squared_error(Y_S_test, S_pred_test_cv)\n",
    "print('testing error: ', mean_squared_error(Y_S_test, S_pred_test_cv))\n",
    "S_models[z]=best_S_model\n",
    "\n",
    "f_i_S=np.zeros(Y_S_test.shape[0])\n",
    "f_i_S[:]=np.NaN\n",
    "for k in np.arange(Y_S_test.shape[0]):\n",
    "    bmask = BernMask(ind=X.columns.to_list(), p=p)\n",
    "\n",
    "    old_coef_S=best_S_model.coef_.reshape((best_S_model.coef_.shape[0],1))\n",
    "    #print(old_coef_P*bmask)\n",
    "    new_coef_S = old_coef_S*bmask\n",
    "    const_S =best_S_model.intercept_\n",
    "    #print('New coef: ', new_coef_P)\n",
    "\n",
    "    # Evaluate new value of P with masked coeff\n",
    "    x_i = X_test.iloc[k,:].to_numpy()\n",
    "    x_i = x_i.reshape((x_i.shape[0],1))\n",
    "    f_i_S[k]=np.dot(new_coef_S.T, x_i)[0,0]+const_S\n",
    "\n",
    "E_S=np.nanmean(f_i_S)\n",
    "var_S = np.nanmean((S_pred_test_cv**2 - E_S**2))\n",
    "S_cv_var[i,j]=var_S\n",
    "print('Dropout E: ', E_S)\n",
    "print('Dropout Var: ', var_S)\n",
    "\n",
    "# # Plot results\n",
    "# fig, axs = plt.subplots(1,2, figsize=(8,6))\n",
    "\n",
    "# x_P = np.arange(np.nanmin([Y_P_test, P_pred_test_cv]),np.nanmax([Y_P_test, P_pred_test_cv])+1)\n",
    "# x_S = np.arange(np.nanmin([Y_S_test, S_pred_test_cv]),np.nanmax([Y_S_test, S_pred_test_cv])+1)\n",
    "\n",
    "# ax = plt.subplot(1,2,1)\n",
    "# ax.scatter(Y_P_test, P_pred_test_cv)\n",
    "# ax.plot(x_P, x_P, 'k-')\n",
    "# ax.set_xlabel('P test (std)')\n",
    "# ax.set_ylabel('P predicted (std)')\n",
    "# ax.set_title('Phosphate')\n",
    "\n",
    "# ax = plt.subplot(1,2,2)\n",
    "# ax.scatter(Y_S_test, S_pred_test_cv)\n",
    "# ax.plot(x_S, x_S, 'k-')\n",
    "# ax.set_xlabel('S test (std)')\n",
    "# ax.set_ylabel('S predicted (std)')\n",
    "# ax.set_title('Silicate')\n",
    "\n",
    "# fig.suptitle('Test Results for: '+pos_encode[i]+' & '+date_encode[j])\n",
    "# plt.subplots_adjust(wspace= .5)\n",
    "\n",
    "# plt.savefig(FigDir+'CV_PosEncode_'+pos_encode[i]+'_DateEncode_'+date_encode[j]+'.jpg')\n",
    "\n",
    "% reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_validate,cross_val_score\n",
    "import torch\n",
    "\n",
    "InputDataDir='data/GOSHIP_Data/QCFilteredData.csv'\n",
    "FigDir = 'figures/LinearRegression_wDropOut/'\n",
    "\n",
    "pos_encode=['raw','radians']\n",
    "date_encode=['thermometer','sincos']\n",
    "\n",
    "P_cv_scores = np.zeros((len(pos_encode), len(date_encode)))\n",
    "P_cv_scores[:]=np.NaN\n",
    "\n",
    "P_cv_Rscores = np.zeros((len(pos_encode), len(date_encode)))\n",
    "P_cv_Rscores[:]=np.NaN\n",
    "\n",
    "P_cv_var = np.zeros((len(pos_encode), len(date_encode)))\n",
    "P_cv_var[:]=np.NaN\n",
    "\n",
    "S_cv_scores = np.zeros((len(pos_encode), len(date_encode)))\n",
    "S_cv_scores[:]=np.NaN\n",
    "\n",
    "S_cv_Rscores = np.zeros((len(pos_encode), len(date_encode)))\n",
    "S_cv_Rscores[:]=np.NaN\n",
    "\n",
    "S_cv_var = np.zeros((len(pos_encode), len(date_encode)))\n",
    "S_cv_var[:]=np.NaN\n",
    "\n",
    "P_models=[[]]*(len(pos_encode)*len(date_encode))\n",
    "S_models=[[]]*(len(pos_encode)*len(date_encode))\n",
    "\n",
    "train_val = int(np.floor(0.9*pd.read_csv(InputDataDir).shape[0]))\n",
    "print('Number training points: ',train_val)\n",
    "print('Total # Data points: ', pd.read_csv(InputDataDir).shape[0])\n",
    "k=10\n",
    "\n",
    "z=0\n",
    "def mean_square_scorer(clf, X, y):\n",
    "    y_pred = clf.predict(X)\n",
    "    cm = mean_squared_error(y, y_pred)\n",
    "    return cm\n",
    "\n",
    "def BernMask(ind, p):\n",
    "    import torch\n",
    "    init_p = torch.empty(len(ind),1)\n",
    "    init_p[:] = p\n",
    "    bmask = torch.bernoulli(init_p)\n",
    "    bmask=np.array(bmask)\n",
    "    #print(bmask)\n",
    "    \n",
    "    return bmask\n",
    "\n",
    "p = 0.7\n",
    "\n",
    "i = 0 \n",
    "j = 1\n",
    "# Load data\n",
    "GOSHIP_Data=pd.read_csv(InputDataDir)\n",
    "GOSHIP_Data=GOSHIP_Data.iloc[:,3:]\n",
    "\n",
    "# Shuffle data\n",
    "GOSHIP_Data = GOSHIP_Data.sample(frac=1)\n",
    "\n",
    "Position_Data = GOSHIP_Data.loc[:,['LATITUDE','LONGITUDE']]\n",
    "Date_Data = GOSHIP_Data.loc[:,'MONTH']\n",
    "\n",
    "# Standardize non-position/datae data\n",
    "scaler = StandardScaler().fit(GOSHIP_Data.iloc[:,2:-1])\n",
    "data_scaled = scaler.transform(GOSHIP_Data.iloc[:,2:-1])\n",
    "data_scaled = pd.DataFrame(data_scaled, columns = ['PRES','TEMP','SAL','OXY','NITR','PHSP','SILI'])\n",
    "\n",
    "# Get X data\n",
    "X=data_scaled.iloc[:,0:5] # Pres, temp, sal , oxy, nitr\n",
    "\n",
    "# Encode position data and add it to X-data\n",
    "if pos_encode[i]=='none':\n",
    "    # Do not include postion data\n",
    "    pass\n",
    "elif pos_encode[i]=='raw':\n",
    "    # Use raw lat/lon data\n",
    "    X['LAT']=GOSHIP_Data.loc[:,'LATITUDE'].to_numpy()\n",
    "    X['LON']=GOSHIP_Data.loc[:,'LONGITUDE'].to_numpy()\n",
    "elif pos_encode[i]=='radians':\n",
    "    # Use lat/lon encoded as radians\n",
    "    X['LAT']=np.radians(GOSHIP_Data.loc[:,'LATITUDE'].to_numpy())\n",
    "    X['LON']=np.radians(GOSHIP_Data.loc[:,'LONGITUDE'].to_numpy())\n",
    "\n",
    "# Encode date data and add it to X-data\n",
    "if date_encode[i]== 'none':\n",
    "    pass\n",
    "elif date_encode[i]== 'thermometer':\n",
    "    non_data=GOSHIP_Data.loc[:,'MONTH'].to_numpy()\n",
    "    temp_data=np.zeros((len(non_data), 12))\n",
    "    for m in np.arange(len(temp_data)):\n",
    "        m_ind=non_data[m]  \n",
    "        temp_data[m,:m_ind]=1\n",
    "\n",
    "    EncodedFeatures=pd.DataFrame(temp_data, columns=['M1','M2','M3', 'M4', 'M5','M6', 'M7', 'M8', 'M9','M10','M11', 'M12'])\n",
    "    #print(EncodedFeatures)\n",
    "    X=pd.concat([X,EncodedFeatures], axis=1)\n",
    "    #print(X)\n",
    "elif date_encode[i]== 'sincos':\n",
    "    # Encode as a sin/cosine pair\n",
    "    X['MONTH_SIN']=np.sin((2*np.pi*GOSHIP_Data.loc[:,'MONTH'])/max(GOSHIP_Data.loc[:,'MONTH']))\n",
    "    X['MONTH_COS']=np.cos((2*np.pi*GOSHIP_Data.loc[:,'MONTH'])/max(GOSHIP_Data.loc[:,'MONTH']))\n",
    "\n",
    "# Get Y data\n",
    "Y_P = data_scaled.loc[:,'PHSP']\n",
    "Y_S = data_scaled.loc[:, 'SILI']\n",
    "\n",
    "# Run regression\n",
    "print('\\nMonth encoding: ', pos_encode[i])\n",
    "print('Date encoding: ', date_encode[j])\n",
    "\n",
    "# Split in to test and train values\n",
    "X_train = X.iloc[:train_val,:]\n",
    "X_test=X.iloc[train_val:, :]\n",
    "\n",
    "Y_P_train=Y_P.iloc[:train_val]\n",
    "Y_P_test=Y_P.iloc[train_val:]\n",
    "\n",
    "Y_S_train=Y_S.iloc[:train_val]\n",
    "Y_S_test=Y_S.iloc[train_val:]\n",
    "\n",
    "ColVal=X.columns.to_list()\n",
    "IndexList=X_train.index.to_list()\n",
    "\n",
    "# For dropout, apply bernoulli mask to training data\n",
    "init_p = torch.empty(X_train.shape)\n",
    "init_p[:] = p\n",
    "bmask_train_array = torch.bernoulli(init_p)\n",
    "bmask_train_array=np.array(bmask_train_array)\n",
    "\n",
    "bmask_train_df=pd.DataFrame(bmask_train_array, index=IndexList, columns=ColVal)\n",
    "X_train=X_train*bmask_train_df\n",
    "# Print Linear regression with cross validation \n",
    "linear=LinearRegression()\n",
    "cv_results_P = cross_validate(linear, X_train, Y_P_train, cv=k,return_train_score=True, scoring=mean_square_scorer, return_estimator=True)\n",
    "cv_results_S = cross_validate(linear, X_train, Y_S_train, cv=k,return_train_score=True,scoring=mean_square_scorer, return_estimator=True)\n",
    "\n",
    "print('\\nCross validation with k-folding: ', k)\n",
    "print('\\n%% PHOSPHATE %%')\n",
    "print('train score: ', cv_results_P['train_score'])\n",
    "print('test score: ', cv_results_P['test_score'])\n",
    "\n",
    "# Select the one with the lowest scores\n",
    "print('Estimator: ', cv_results_P['estimator'][np.argmin(cv_results_P['test_score'])].coef_)\n",
    "best_P_model = cv_results_P['estimator'][np.argmin(cv_results_P['test_score'])]\n",
    "print('R2 values: ',best_P_model.score(X_train,Y_P_train))\n",
    "P_models[z]=best_P_model\n",
    "# Test this model and calculate MSE on test data\n",
    "P_pred_test_cv=best_P_model.predict(X_test)\n",
    "P_cv_Rscores[i,j]=best_P_model.score(X_train,Y_P_train)\n",
    "P_cv_scores[i,j]=mean_squared_error(Y_P_test, P_pred_test_cv)\n",
    "print('testing error: ', mean_squared_error(Y_P_test, P_pred_test_cv))\n",
    "\n",
    "## Droup out testing\n",
    "# Calculate E\n",
    "f_i_P=np.zeros(Y_P_test.shape[0])\n",
    "f_i_P[:]=np.NaN\n",
    "for k in np.arange(Y_P_test.shape[0]):\n",
    "    bmask = BernMask(ind=X.columns.to_list(), p=p)\n",
    "\n",
    "    old_coef_P=best_P_model.coef_.reshape((best_P_model.coef_.shape[0],1))\n",
    "    #print(old_coef_P*bmask)\n",
    "    new_coef_P = old_coef_P*bmask\n",
    "    const_P =best_P_model.intercept_\n",
    "    #print('New coef: ', new_coef_P)\n",
    "\n",
    "    # Evaluate new value of P with masked coeff\n",
    "    x_i = X_test.iloc[k,:].to_numpy()\n",
    "    x_i = x_i.reshape((x_i.shape[0],1))\n",
    "    f_i_P[k]=np.dot(new_coef_P.T, x_i)[0,0]+const_P\n",
    "\n",
    "E_P=np.nanmean(f_i_P)\n",
    "var_P = np.nanmean((P_pred_test_cv**2 - E_P**2))\n",
    "P_cv_var[i,j]=var_P\n",
    "\n",
    "print('Dropout E: ', E_P)\n",
    "print('Dropout Var: ', var_P)\n",
    "\n",
    "print('\\n%% SILICATE %%')\n",
    "\n",
    "print('train score: ', cv_results_S['train_score'])\n",
    "print('test score: ', cv_results_S['test_score'])\n",
    "print('Estimator: ', cv_results_S['estimator'][np.argmin(cv_results_S['test_score'])].coef_)\n",
    "best_S_model = cv_results_S['estimator'][np.argmin(cv_results_S['test_score'])]\n",
    "print('R2 values: ',best_S_model.score(X_train,Y_S_train))\n",
    "S_pred_test_cv=best_S_model.predict(X_test)\n",
    "S_cv_Rscores[i,j]=best_S_model.score(X_train,Y_S_train)\n",
    "S_cv_scores[i,j]=mean_squared_error(Y_S_test, S_pred_test_cv)\n",
    "print('testing error: ', mean_squared_error(Y_S_test, S_pred_test_cv))\n",
    "S_models[z]=best_S_model\n",
    "\n",
    "f_i_S=np.zeros(Y_S_test.shape[0])\n",
    "f_i_S[:]=np.NaN\n",
    "for k in np.arange(Y_S_test.shape[0]):\n",
    "    bmask = BernMask(ind=X.columns.to_list(), p=p)\n",
    "\n",
    "    old_coef_S=best_S_model.coef_.reshape((best_S_model.coef_.shape[0],1))\n",
    "    #print(old_coef_P*bmask)\n",
    "    new_coef_S = old_coef_S*bmask\n",
    "    const_S =best_S_model.intercept_\n",
    "    #print('New coef: ', new_coef_P)\n",
    "\n",
    "    # Evaluate new value of P with masked coeff\n",
    "    x_i = X_test.iloc[k,:].to_numpy()\n",
    "    x_i = x_i.reshape((x_i.shape[0],1))\n",
    "    f_i_S[k]=np.dot(new_coef_S.T, x_i)[0,0]+const_S\n",
    "\n",
    "E_S=np.nanmean(f_i_S)\n",
    "var_S = np.nanmean((S_pred_test_cv**2 - E_S**2))\n",
    "S_cv_var[i,j]=var_S\n",
    "print('Dropout E: ', E_S)\n",
    "print('Dropout Var: ', var_S)\n",
    "\n",
    "# # Plot results\n",
    "# fig, axs = plt.subplots(1,2, figsize=(8,6))\n",
    "\n",
    "# x_P = np.arange(np.nanmin([Y_P_test, P_pred_test_cv]),np.nanmax([Y_P_test, P_pred_test_cv])+1)\n",
    "# x_S = np.arange(np.nanmin([Y_S_test, S_pred_test_cv]),np.nanmax([Y_S_test, S_pred_test_cv])+1)\n",
    "\n",
    "# ax = plt.subplot(1,2,1)\n",
    "# ax.scatter(Y_P_test, P_pred_test_cv)\n",
    "# ax.plot(x_P, x_P, 'k-')\n",
    "# ax.set_xlabel('P test (std)')\n",
    "# ax.set_ylabel('P predicted (std)')\n",
    "# ax.set_title('Phosphate')\n",
    "\n",
    "# ax = plt.subplot(1,2,2)\n",
    "# ax.scatter(Y_S_test, S_pred_test_cv)\n",
    "# ax.plot(x_S, x_S, 'k-')\n",
    "# ax.set_xlabel('S test (std)')\n",
    "# ax.set_ylabel('S predicted (std)')\n",
    "# ax.set_title('Silicate')\n",
    "\n",
    "# fig.suptitle('Test Results for: '+pos_encode[i]+' & '+date_encode[j])\n",
    "# plt.subplots_adjust(wspace= .5)\n",
    "\n",
    "# plt.savefig(FigDir+'CV_PosEncode_'+pos_encode[i]+'_DateEncode_'+date_encode[j]+'.jpg')\n",
    "\n",
    "% reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_validate,cross_val_score\n",
    "import torch\n",
    "\n",
    "InputDataDir='data/GOSHIP_Data/QCFilteredData.csv'\n",
    "FigDir = 'figures/LinearRegression_wDropOut/'\n",
    "\n",
    "pos_encode=['raw','radians']\n",
    "date_encode=['thermometer','sincos']\n",
    "\n",
    "P_cv_scores = np.zeros((len(pos_encode), len(date_encode)))\n",
    "P_cv_scores[:]=np.NaN\n",
    "\n",
    "P_cv_Rscores = np.zeros((len(pos_encode), len(date_encode)))\n",
    "P_cv_Rscores[:]=np.NaN\n",
    "\n",
    "P_cv_var = np.zeros((len(pos_encode), len(date_encode)))\n",
    "P_cv_var[:]=np.NaN\n",
    "\n",
    "S_cv_scores = np.zeros((len(pos_encode), len(date_encode)))\n",
    "S_cv_scores[:]=np.NaN\n",
    "\n",
    "S_cv_Rscores = np.zeros((len(pos_encode), len(date_encode)))\n",
    "S_cv_Rscores[:]=np.NaN\n",
    "\n",
    "S_cv_var = np.zeros((len(pos_encode), len(date_encode)))\n",
    "S_cv_var[:]=np.NaN\n",
    "\n",
    "P_models=[[]]*(len(pos_encode)*len(date_encode))\n",
    "S_models=[[]]*(len(pos_encode)*len(date_encode))\n",
    "\n",
    "train_val = int(np.floor(0.9*pd.read_csv(InputDataDir).shape[0]))\n",
    "print('Number training points: ',train_val)\n",
    "print('Total # Data points: ', pd.read_csv(InputDataDir).shape[0])\n",
    "k=10\n",
    "\n",
    "z=0\n",
    "def mean_square_scorer(clf, X, y):\n",
    "    y_pred = clf.predict(X)\n",
    "    cm = mean_squared_error(y, y_pred)\n",
    "    return cm\n",
    "\n",
    "def BernMask(ind, p):\n",
    "    import torch\n",
    "    init_p = torch.empty(len(ind),1)\n",
    "    init_p[:] = p\n",
    "    bmask = torch.bernoulli(init_p)\n",
    "    bmask=np.array(bmask)\n",
    "    #print(bmask)\n",
    "    \n",
    "    return bmask\n",
    "\n",
    "p = 0.7\n",
    "\n",
    "i = 1 \n",
    "j = 0\n",
    "# Load data\n",
    "GOSHIP_Data=pd.read_csv(InputDataDir)\n",
    "GOSHIP_Data=GOSHIP_Data.iloc[:,3:]\n",
    "\n",
    "# Shuffle data\n",
    "GOSHIP_Data = GOSHIP_Data.sample(frac=1)\n",
    "\n",
    "Position_Data = GOSHIP_Data.loc[:,['LATITUDE','LONGITUDE']]\n",
    "Date_Data = GOSHIP_Data.loc[:,'MONTH']\n",
    "\n",
    "# Standardize non-position/datae data\n",
    "scaler = StandardScaler().fit(GOSHIP_Data.iloc[:,2:-1])\n",
    "data_scaled = scaler.transform(GOSHIP_Data.iloc[:,2:-1])\n",
    "data_scaled = pd.DataFrame(data_scaled, columns = ['PRES','TEMP','SAL','OXY','NITR','PHSP','SILI'])\n",
    "\n",
    "# Get X data\n",
    "X=data_scaled.iloc[:,0:5] # Pres, temp, sal , oxy, nitr\n",
    "\n",
    "# Encode position data and add it to X-data\n",
    "if pos_encode[i]=='none':\n",
    "    # Do not include postion data\n",
    "    pass\n",
    "elif pos_encode[i]=='raw':\n",
    "    # Use raw lat/lon data\n",
    "    X['LAT']=GOSHIP_Data.loc[:,'LATITUDE'].to_numpy()\n",
    "    X['LON']=GOSHIP_Data.loc[:,'LONGITUDE'].to_numpy()\n",
    "elif pos_encode[i]=='radians':\n",
    "    # Use lat/lon encoded as radians\n",
    "    X['LAT']=np.radians(GOSHIP_Data.loc[:,'LATITUDE'].to_numpy())\n",
    "    X['LON']=np.radians(GOSHIP_Data.loc[:,'LONGITUDE'].to_numpy())\n",
    "\n",
    "# Encode date data and add it to X-data\n",
    "if date_encode[i]== 'none':\n",
    "    pass\n",
    "elif date_encode[i]== 'thermometer':\n",
    "    non_data=GOSHIP_Data.loc[:,'MONTH'].to_numpy()\n",
    "    temp_data=np.zeros((len(non_data), 12))\n",
    "    for m in np.arange(len(temp_data)):\n",
    "        m_ind=non_data[m]  \n",
    "        temp_data[m,:m_ind]=1\n",
    "\n",
    "    EncodedFeatures=pd.DataFrame(temp_data, columns=['M1','M2','M3', 'M4', 'M5','M6', 'M7', 'M8', 'M9','M10','M11', 'M12'])\n",
    "    #print(EncodedFeatures)\n",
    "    X=pd.concat([X,EncodedFeatures], axis=1)\n",
    "    #print(X)\n",
    "elif date_encode[i]== 'sincos':\n",
    "    # Encode as a sin/cosine pair\n",
    "    X['MONTH_SIN']=np.sin((2*np.pi*GOSHIP_Data.loc[:,'MONTH'])/max(GOSHIP_Data.loc[:,'MONTH']))\n",
    "    X['MONTH_COS']=np.cos((2*np.pi*GOSHIP_Data.loc[:,'MONTH'])/max(GOSHIP_Data.loc[:,'MONTH']))\n",
    "\n",
    "# Get Y data\n",
    "Y_P = data_scaled.loc[:,'PHSP']\n",
    "Y_S = data_scaled.loc[:, 'SILI']\n",
    "\n",
    "# Run regression\n",
    "print('\\nMonth encoding: ', pos_encode[i])\n",
    "print('Date encoding: ', date_encode[j])\n",
    "\n",
    "# Split in to test and train values\n",
    "X_train = X.iloc[:train_val,:]\n",
    "X_test=X.iloc[train_val:, :]\n",
    "\n",
    "Y_P_train=Y_P.iloc[:train_val]\n",
    "Y_P_test=Y_P.iloc[train_val:]\n",
    "\n",
    "Y_S_train=Y_S.iloc[:train_val]\n",
    "Y_S_test=Y_S.iloc[train_val:]\n",
    "\n",
    "ColVal=X.columns.to_list()\n",
    "IndexList=X_train.index.to_list()\n",
    "\n",
    "# For dropout, apply bernoulli mask to training data\n",
    "init_p = torch.empty(X_train.shape)\n",
    "init_p[:] = p\n",
    "bmask_train_array = torch.bernoulli(init_p)\n",
    "bmask_train_array=np.array(bmask_train_array)\n",
    "\n",
    "bmask_train_df=pd.DataFrame(bmask_train_array, index=IndexList, columns=ColVal)\n",
    "X_train=X_train*bmask_train_df\n",
    "# Print Linear regression with cross validation \n",
    "linear=LinearRegression()\n",
    "cv_results_P = cross_validate(linear, X_train, Y_P_train, cv=k,return_train_score=True, scoring=mean_square_scorer, return_estimator=True)\n",
    "cv_results_S = cross_validate(linear, X_train, Y_S_train, cv=k,return_train_score=True,scoring=mean_square_scorer, return_estimator=True)\n",
    "\n",
    "print('\\nCross validation with k-folding: ', k)\n",
    "print('\\n%% PHOSPHATE %%')\n",
    "print('train score: ', cv_results_P['train_score'])\n",
    "print('test score: ', cv_results_P['test_score'])\n",
    "\n",
    "# Select the one with the lowest scores\n",
    "print('Estimator: ', cv_results_P['estimator'][np.argmin(cv_results_P['test_score'])].coef_)\n",
    "best_P_model = cv_results_P['estimator'][np.argmin(cv_results_P['test_score'])]\n",
    "print('R2 values: ',best_P_model.score(X_train,Y_P_train))\n",
    "P_models[z]=best_P_model\n",
    "# Test this model and calculate MSE on test data\n",
    "P_pred_test_cv=best_P_model.predict(X_test)\n",
    "P_cv_Rscores[i,j]=best_P_model.score(X_train,Y_P_train)\n",
    "P_cv_scores[i,j]=mean_squared_error(Y_P_test, P_pred_test_cv)\n",
    "print('testing error: ', mean_squared_error(Y_P_test, P_pred_test_cv))\n",
    "\n",
    "## Droup out testing\n",
    "# Calculate E\n",
    "f_i_P=np.zeros(Y_P_test.shape[0])\n",
    "f_i_P[:]=np.NaN\n",
    "for k in np.arange(Y_P_test.shape[0]):\n",
    "    bmask = BernMask(ind=X.columns.to_list(), p=p)\n",
    "\n",
    "    old_coef_P=best_P_model.coef_.reshape((best_P_model.coef_.shape[0],1))\n",
    "    #print(old_coef_P*bmask)\n",
    "    new_coef_P = old_coef_P*bmask\n",
    "    const_P =best_P_model.intercept_\n",
    "    #print('New coef: ', new_coef_P)\n",
    "\n",
    "    # Evaluate new value of P with masked coeff\n",
    "    x_i = X_test.iloc[k,:].to_numpy()\n",
    "    x_i = x_i.reshape((x_i.shape[0],1))\n",
    "    f_i_P[k]=np.dot(new_coef_P.T, x_i)[0,0]+const_P\n",
    "\n",
    "E_P=np.nanmean(f_i_P)\n",
    "var_P = np.nanmean((P_pred_test_cv**2 - E_P**2))\n",
    "P_cv_var[i,j]=var_P\n",
    "\n",
    "print('Dropout E: ', E_P)\n",
    "print('Dropout Var: ', var_P)\n",
    "\n",
    "print('\\n%% SILICATE %%')\n",
    "\n",
    "print('train score: ', cv_results_S['train_score'])\n",
    "print('test score: ', cv_results_S['test_score'])\n",
    "print('Estimator: ', cv_results_S['estimator'][np.argmin(cv_results_S['test_score'])].coef_)\n",
    "best_S_model = cv_results_S['estimator'][np.argmin(cv_results_S['test_score'])]\n",
    "print('R2 values: ',best_S_model.score(X_train,Y_S_train))\n",
    "S_pred_test_cv=best_S_model.predict(X_test)\n",
    "S_cv_Rscores[i,j]=best_S_model.score(X_train,Y_S_train)\n",
    "S_cv_scores[i,j]=mean_squared_error(Y_S_test, S_pred_test_cv)\n",
    "print('testing error: ', mean_squared_error(Y_S_test, S_pred_test_cv))\n",
    "S_models[z]=best_S_model\n",
    "\n",
    "f_i_S=np.zeros(Y_S_test.shape[0])\n",
    "f_i_S[:]=np.NaN\n",
    "for k in np.arange(Y_S_test.shape[0]):\n",
    "    bmask = BernMask(ind=X.columns.to_list(), p=p)\n",
    "\n",
    "    old_coef_S=best_S_model.coef_.reshape((best_S_model.coef_.shape[0],1))\n",
    "    #print(old_coef_P*bmask)\n",
    "    new_coef_S = old_coef_S*bmask\n",
    "    const_S =best_S_model.intercept_\n",
    "    #print('New coef: ', new_coef_P)\n",
    "\n",
    "    # Evaluate new value of P with masked coeff\n",
    "    x_i = X_test.iloc[k,:].to_numpy()\n",
    "    x_i = x_i.reshape((x_i.shape[0],1))\n",
    "    f_i_S[k]=np.dot(new_coef_S.T, x_i)[0,0]+const_S\n",
    "\n",
    "E_S=np.nanmean(f_i_S)\n",
    "var_S = np.nanmean((S_pred_test_cv**2 - E_S**2))\n",
    "S_cv_var[i,j]=var_S\n",
    "print('Dropout E: ', E_S)\n",
    "print('Dropout Var: ', var_S)\n",
    "\n",
    "# # Plot results\n",
    "# fig, axs = plt.subplots(1,2, figsize=(8,6))\n",
    "\n",
    "# x_P = np.arange(np.nanmin([Y_P_test, P_pred_test_cv]),np.nanmax([Y_P_test, P_pred_test_cv])+1)\n",
    "# x_S = np.arange(np.nanmin([Y_S_test, S_pred_test_cv]),np.nanmax([Y_S_test, S_pred_test_cv])+1)\n",
    "\n",
    "# ax = plt.subplot(1,2,1)\n",
    "# ax.scatter(Y_P_test, P_pred_test_cv)\n",
    "# ax.plot(x_P, x_P, 'k-')\n",
    "# ax.set_xlabel('P test (std)')\n",
    "# ax.set_ylabel('P predicted (std)')\n",
    "# ax.set_title('Phosphate')\n",
    "\n",
    "# ax = plt.subplot(1,2,2)\n",
    "# ax.scatter(Y_S_test, S_pred_test_cv)\n",
    "# ax.plot(x_S, x_S, 'k-')\n",
    "# ax.set_xlabel('S test (std)')\n",
    "# ax.set_ylabel('S predicted (std)')\n",
    "# ax.set_title('Silicate')\n",
    "\n",
    "# fig.suptitle('Test Results for: '+pos_encode[i]+' & '+date_encode[j])\n",
    "# plt.subplots_adjust(wspace= .5)\n",
    "\n",
    "# plt.savefig(FigDir+'CV_PosEncode_'+pos_encode[i]+'_DateEncode_'+date_encode[j]+'.jpg')\n",
    "\n",
    "% reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_validate,cross_val_score\n",
    "import torch\n",
    "\n",
    "InputDataDir='data/GOSHIP_Data/QCFilteredData.csv'\n",
    "FigDir = 'figures/LinearRegression_wDropOut/'\n",
    "\n",
    "pos_encode=['raw','radians']\n",
    "date_encode=['thermometer','sincos']\n",
    "\n",
    "P_cv_scores = np.zeros((len(pos_encode), len(date_encode)))\n",
    "P_cv_scores[:]=np.NaN\n",
    "\n",
    "P_cv_Rscores = np.zeros((len(pos_encode), len(date_encode)))\n",
    "P_cv_Rscores[:]=np.NaN\n",
    "\n",
    "P_cv_var = np.zeros((len(pos_encode), len(date_encode)))\n",
    "P_cv_var[:]=np.NaN\n",
    "\n",
    "S_cv_scores = np.zeros((len(pos_encode), len(date_encode)))\n",
    "S_cv_scores[:]=np.NaN\n",
    "\n",
    "S_cv_Rscores = np.zeros((len(pos_encode), len(date_encode)))\n",
    "S_cv_Rscores[:]=np.NaN\n",
    "\n",
    "S_cv_var = np.zeros((len(pos_encode), len(date_encode)))\n",
    "S_cv_var[:]=np.NaN\n",
    "\n",
    "P_models=[[]]*(len(pos_encode)*len(date_encode))\n",
    "S_models=[[]]*(len(pos_encode)*len(date_encode))\n",
    "\n",
    "train_val = int(np.floor(0.9*pd.read_csv(InputDataDir).shape[0]))\n",
    "print('Number training points: ',train_val)\n",
    "print('Total # Data points: ', pd.read_csv(InputDataDir).shape[0])\n",
    "k=10\n",
    "\n",
    "z=0\n",
    "def mean_square_scorer(clf, X, y):\n",
    "    y_pred = clf.predict(X)\n",
    "    cm = mean_squared_error(y, y_pred)\n",
    "    return cm\n",
    "\n",
    "def BernMask(ind, p):\n",
    "    import torch\n",
    "    init_p = torch.empty(len(ind),1)\n",
    "    init_p[:] = p\n",
    "    bmask = torch.bernoulli(init_p)\n",
    "    bmask=np.array(bmask)\n",
    "    #print(bmask)\n",
    "    \n",
    "    return bmask\n",
    "\n",
    "p = 0.7\n",
    "\n",
    "i = 1 \n",
    "j = 1\n",
    "# Load data\n",
    "GOSHIP_Data=pd.read_csv(InputDataDir)\n",
    "GOSHIP_Data=GOSHIP_Data.iloc[:,3:]\n",
    "\n",
    "# Shuffle data\n",
    "GOSHIP_Data = GOSHIP_Data.sample(frac=1)\n",
    "\n",
    "Position_Data = GOSHIP_Data.loc[:,['LATITUDE','LONGITUDE']]\n",
    "Date_Data = GOSHIP_Data.loc[:,'MONTH']\n",
    "\n",
    "# Standardize non-position/datae data\n",
    "scaler = StandardScaler().fit(GOSHIP_Data.iloc[:,2:-1])\n",
    "data_scaled = scaler.transform(GOSHIP_Data.iloc[:,2:-1])\n",
    "data_scaled = pd.DataFrame(data_scaled, columns = ['PRES','TEMP','SAL','OXY','NITR','PHSP','SILI'])\n",
    "\n",
    "# Get X data\n",
    "X=data_scaled.iloc[:,0:5] # Pres, temp, sal , oxy, nitr\n",
    "\n",
    "# Encode position data and add it to X-data\n",
    "if pos_encode[i]=='none':\n",
    "    # Do not include postion data\n",
    "    pass\n",
    "elif pos_encode[i]=='raw':\n",
    "    # Use raw lat/lon data\n",
    "    X['LAT']=GOSHIP_Data.loc[:,'LATITUDE'].to_numpy()\n",
    "    X['LON']=GOSHIP_Data.loc[:,'LONGITUDE'].to_numpy()\n",
    "elif pos_encode[i]=='radians':\n",
    "    # Use lat/lon encoded as radians\n",
    "    X['LAT']=np.radians(GOSHIP_Data.loc[:,'LATITUDE'].to_numpy())\n",
    "    X['LON']=np.radians(GOSHIP_Data.loc[:,'LONGITUDE'].to_numpy())\n",
    "\n",
    "# Encode date data and add it to X-data\n",
    "if date_encode[i]== 'none':\n",
    "    pass\n",
    "elif date_encode[i]== 'thermometer':\n",
    "    non_data=GOSHIP_Data.loc[:,'MONTH'].to_numpy()\n",
    "    temp_data=np.zeros((len(non_data), 12))\n",
    "    for m in np.arange(len(temp_data)):\n",
    "        m_ind=non_data[m]  \n",
    "        temp_data[m,:m_ind]=1\n",
    "\n",
    "    EncodedFeatures=pd.DataFrame(temp_data, columns=['M1','M2','M3', 'M4', 'M5','M6', 'M7', 'M8', 'M9','M10','M11', 'M12'])\n",
    "    #print(EncodedFeatures)\n",
    "    X=pd.concat([X,EncodedFeatures], axis=1)\n",
    "    #print(X)\n",
    "elif date_encode[i]== 'sincos':\n",
    "    # Encode as a sin/cosine pair\n",
    "    X['MONTH_SIN']=np.sin((2*np.pi*GOSHIP_Data.loc[:,'MONTH'])/max(GOSHIP_Data.loc[:,'MONTH']))\n",
    "    X['MONTH_COS']=np.cos((2*np.pi*GOSHIP_Data.loc[:,'MONTH'])/max(GOSHIP_Data.loc[:,'MONTH']))\n",
    "\n",
    "# Get Y data\n",
    "Y_P = data_scaled.loc[:,'PHSP']\n",
    "Y_S = data_scaled.loc[:, 'SILI']\n",
    "\n",
    "# Run regression\n",
    "print('\\nMonth encoding: ', pos_encode[i])\n",
    "print('Date encoding: ', date_encode[j])\n",
    "\n",
    "# Split in to test and train values\n",
    "X_train = X.iloc[:train_val,:]\n",
    "X_test=X.iloc[train_val:, :]\n",
    "\n",
    "Y_P_train=Y_P.iloc[:train_val]\n",
    "Y_P_test=Y_P.iloc[train_val:]\n",
    "\n",
    "Y_S_train=Y_S.iloc[:train_val]\n",
    "Y_S_test=Y_S.iloc[train_val:]\n",
    "\n",
    "ColVal=X.columns.to_list()\n",
    "IndexList=X_train.index.to_list()\n",
    "\n",
    "# For dropout, apply bernoulli mask to training data\n",
    "init_p = torch.empty(X_train.shape)\n",
    "init_p[:] = p\n",
    "bmask_train_array = torch.bernoulli(init_p)\n",
    "bmask_train_array=np.array(bmask_train_array)\n",
    "\n",
    "bmask_train_df=pd.DataFrame(bmask_train_array, index=IndexList, columns=ColVal)\n",
    "X_train=X_train*bmask_train_df\n",
    "# Print Linear regression with cross validation \n",
    "linear=LinearRegression()\n",
    "cv_results_P = cross_validate(linear, X_train, Y_P_train, cv=k,return_train_score=True, scoring=mean_square_scorer, return_estimator=True)\n",
    "cv_results_S = cross_validate(linear, X_train, Y_S_train, cv=k,return_train_score=True,scoring=mean_square_scorer, return_estimator=True)\n",
    "\n",
    "print('\\nCross validation with k-folding: ', k)\n",
    "print('\\n%% PHOSPHATE %%')\n",
    "print('train score: ', cv_results_P['train_score'])\n",
    "print('test score: ', cv_results_P['test_score'])\n",
    "\n",
    "# Select the one with the lowest scores\n",
    "print('Estimator: ', cv_results_P['estimator'][np.argmin(cv_results_P['test_score'])].coef_)\n",
    "best_P_model = cv_results_P['estimator'][np.argmin(cv_results_P['test_score'])]\n",
    "print('R2 values: ',best_P_model.score(X_train,Y_P_train))\n",
    "P_models[z]=best_P_model\n",
    "# Test this model and calculate MSE on test data\n",
    "P_pred_test_cv=best_P_model.predict(X_test)\n",
    "P_cv_Rscores[i,j]=best_P_model.score(X_train,Y_P_train)\n",
    "P_cv_scores[i,j]=mean_squared_error(Y_P_test, P_pred_test_cv)\n",
    "print('testing error: ', mean_squared_error(Y_P_test, P_pred_test_cv))\n",
    "\n",
    "## Droup out testing\n",
    "# Calculate E\n",
    "f_i_P=np.zeros(Y_P_test.shape[0])\n",
    "f_i_P[:]=np.NaN\n",
    "for k in np.arange(Y_P_test.shape[0]):\n",
    "    bmask = BernMask(ind=X.columns.to_list(), p=p)\n",
    "\n",
    "    old_coef_P=best_P_model.coef_.reshape((best_P_model.coef_.shape[0],1))\n",
    "    #print(old_coef_P*bmask)\n",
    "    new_coef_P = old_coef_P*bmask\n",
    "    const_P =best_P_model.intercept_\n",
    "    #print('New coef: ', new_coef_P)\n",
    "\n",
    "    # Evaluate new value of P with masked coeff\n",
    "    x_i = X_test.iloc[k,:].to_numpy()\n",
    "    x_i = x_i.reshape((x_i.shape[0],1))\n",
    "    f_i_P[k]=np.dot(new_coef_P.T, x_i)[0,0]+const_P\n",
    "\n",
    "E_P=np.nanmean(f_i_P)\n",
    "var_P = np.nanmean((P_pred_test_cv**2 - E_P**2))\n",
    "P_cv_var[i,j]=var_P\n",
    "\n",
    "print('Dropout E: ', E_P)\n",
    "print('Dropout Var: ', var_P)\n",
    "\n",
    "print('\\n%% SILICATE %%')\n",
    "\n",
    "print('train score: ', cv_results_S['train_score'])\n",
    "print('test score: ', cv_results_S['test_score'])\n",
    "print('Estimator: ', cv_results_S['estimator'][np.argmin(cv_results_S['test_score'])].coef_)\n",
    "best_S_model = cv_results_S['estimator'][np.argmin(cv_results_S['test_score'])]\n",
    "print('R2 values: ',best_S_model.score(X_train,Y_S_train))\n",
    "S_pred_test_cv=best_S_model.predict(X_test)\n",
    "S_cv_Rscores[i,j]=best_S_model.score(X_train,Y_S_train)\n",
    "S_cv_scores[i,j]=mean_squared_error(Y_S_test, S_pred_test_cv)\n",
    "print('testing error: ', mean_squared_error(Y_S_test, S_pred_test_cv))\n",
    "S_models[z]=best_S_model\n",
    "\n",
    "f_i_S=np.zeros(Y_S_test.shape[0])\n",
    "f_i_S[:]=np.NaN\n",
    "for k in np.arange(Y_S_test.shape[0]):\n",
    "    bmask = BernMask(ind=X.columns.to_list(), p=p)\n",
    "\n",
    "    old_coef_S=best_S_model.coef_.reshape((best_S_model.coef_.shape[0],1))\n",
    "    #print(old_coef_P*bmask)\n",
    "    new_coef_S = old_coef_S*bmask\n",
    "    const_S =best_S_model.intercept_\n",
    "    #print('New coef: ', new_coef_P)\n",
    "\n",
    "    # Evaluate new value of P with masked coeff\n",
    "    x_i = X_test.iloc[k,:].to_numpy()\n",
    "    x_i = x_i.reshape((x_i.shape[0],1))\n",
    "    f_i_S[k]=np.dot(new_coef_S.T, x_i)[0,0]+const_S\n",
    "\n",
    "E_S=np.nanmean(f_i_S)\n",
    "var_S = np.nanmean((S_pred_test_cv**2 - E_S**2))\n",
    "S_cv_var[i,j]=var_S\n",
    "print('Dropout E: ', E_S)\n",
    "print('Dropout Var: ', var_S)\n",
    "\n",
    "# # Plot results\n",
    "# fig, axs = plt.subplots(1,2, figsize=(8,6))\n",
    "\n",
    "# x_P = np.arange(np.nanmin([Y_P_test, P_pred_test_cv]),np.nanmax([Y_P_test, P_pred_test_cv])+1)\n",
    "# x_S = np.arange(np.nanmin([Y_S_test, S_pred_test_cv]),np.nanmax([Y_S_test, S_pred_test_cv])+1)\n",
    "\n",
    "# ax = plt.subplot(1,2,1)\n",
    "# ax.scatter(Y_P_test, P_pred_test_cv)\n",
    "# ax.plot(x_P, x_P, 'k-')\n",
    "# ax.set_xlabel('P test (std)')\n",
    "# ax.set_ylabel('P predicted (std)')\n",
    "# ax.set_title('Phosphate')\n",
    "\n",
    "# ax = plt.subplot(1,2,2)\n",
    "# ax.scatter(Y_S_test, S_pred_test_cv)\n",
    "# ax.plot(x_S, x_S, 'k-')\n",
    "# ax.set_xlabel('S test (std)')\n",
    "# ax.set_ylabel('S predicted (std)')\n",
    "# ax.set_title('Silicate')\n",
    "\n",
    "# fig.suptitle('Test Results for: '+pos_encode[i]+' & '+date_encode[j])\n",
    "# plt.subplots_adjust(wspace= .5)\n",
    "\n",
    "# plt.savefig(FigDir+'CV_PosEncode_'+pos_encode[i]+'_DateEncode_'+date_encode[j]+'.jpg')\n",
    "\n",
    "% reset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:BCenv] *",
   "language": "python",
   "name": "conda-env-BCenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
